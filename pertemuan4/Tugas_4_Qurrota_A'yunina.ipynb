{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8f5448fb",
      "metadata": {
        "id": "8f5448fb",
        "papermill": {
          "duration": 0.014281,
          "end_time": "2024-06-29T05:06:57.857497",
          "exception": false,
          "start_time": "2024-06-29T05:06:57.843216",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# **Stacking from scratch**\n",
        "\n",
        "Berikan penjelasan terkait Stacking!\n",
        "\n",
        "Source : https://www.geeksforgeeks.org/machine-learning/stacking-in-machine-learning/\n",
        "Youtube : https://www.youtube.com/watch?v=a4IS1Ai7GCI\n",
        "\n",
        "Stacking atau stacked generalization adalah teknik ensemble learning yang menggabungkan beberapa model dasar (base models) melalui satu model meta (meta-model) untuk meningkatkan akurasi prediksi. Tujuannya adalah memanfaatkan kelebihan tiap model dan mengurangi kelemahannya sehingga hasil prediksi menjadi lebih baik.\n",
        "\n",
        "Proses stacking terdiri dari dua lapisan. Lapisan pertama berisi base models seperti Decision Tree, KNN, Logistic Regression, atau SVM yang belajar langsung dari data pelatihan. Lapisan kedua adalah meta model yang menerima hasil prediksi dari model-model dasar sebagai input dan menghasilkan prediksi akhir. Biasanya, meta model berupa model sederhana seperti Logistic Regression agar tidak mudah overfitting.\n",
        "\n",
        "Cara kerja stacking dilakukan dengan melatih model dasar pada data pelatihan, lalu menghasilkan prediksi pada data yang tidak digunakan untuk pelatihan (out-of-fold prediction). Prediksi ini kemudian dijadikan data baru untuk melatih meta model. Saat melakukan prediksi, base models memberikan hasil awal yang digabung oleh meta model untuk menghasilkan keputusan akhir.\n",
        "\n",
        "Keunggulan stacking adalah mampu meningkatkan performa dan stabilitas prediksi karena mengombinasikan berbagai algoritma. Namun, teknik ini lebih kompleks, memakan waktu pelatihan lebih lama, dan berisiko overfitting jika tidak diatur dengan baik.\n",
        "\n",
        "Menurut GeeksforGeeks, implementasi stacking dapat dilakukan menggunakan StackingClassifier dari scikit-learn dengan contoh model KNN dan Naive Bayes sebagai base models, serta Logistic Regression sebagai meta model. Hasilnya menunjukkan peningkatan akurasi dibanding model tunggal, menjadikan stacking salah satu metode ensemble yang efektif dalam machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "1586bc8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-29T05:06:57.888286Z",
          "iopub.status.busy": "2024-06-29T05:06:57.887851Z",
          "iopub.status.idle": "2024-06-29T05:07:00.846336Z",
          "shell.execute_reply": "2024-06-29T05:07:00.845160Z"
        },
        "id": "1586bc8f",
        "papermill": {
          "duration": 2.977168,
          "end_time": "2024-06-29T05:07:00.849030",
          "exception": false,
          "start_time": "2024-06-29T05:06:57.871862",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pendefinisian class stack**\n",
        "\n",
        "Bertujuan untuk membuat kerangka kerja ensemble learning berbasis stacking dan blending secara modular dan fleksibel. Class ini memungkinkan pengguna untuk menggabungkan beberapa model dasar (base learners) dan satu model meta (final estimator) untuk menghasilkan prediksi akhir yang lebih akurat. Dengan mengatur parameter seperti metode cross-validation, penggunaan blending, serta paralelisasi proses, class ini memberikan kontrol penuh kepada pengguna dalam menerapkan teknik stacking sesuai kebutuhan. Kegunaan utamanya adalah sebagai alat bantu untuk mengimplementasikan ensemble model dari nol (from scratch) tanpa tergantung pada fungsi otomatis dari pustaka seperti scikit-learn, sehingga cocok untuk pembelajaran konsep maupun eksperimen lanjutan dalam machine learning."
      ],
      "metadata": {
        "id": "xl_ZCQOqltFo"
      },
      "id": "xl_ZCQOqltFo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buat class bernama Stack yang berisi <br>\n",
        "\n",
        "Attribute:\n",
        "\n",
        "\n",
        "Method:\n"
      ],
      "metadata": {
        "id": "_hxe6ClnA8_o"
      },
      "id": "_hxe6ClnA8_o"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "436db242",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-29T05:07:00.881581Z",
          "iopub.status.busy": "2024-06-29T05:07:00.880255Z",
          "iopub.status.idle": "2024-06-29T05:07:00.897475Z",
          "shell.execute_reply": "2024-06-29T05:07:00.896334Z"
        },
        "id": "436db242",
        "papermill": {
          "duration": 0.036178,
          "end_time": "2024-06-29T05:07:00.900303",
          "exception": false,
          "start_time": "2024-06-29T05:07:00.864125",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Definisikan class stack\n",
        "# Definisikan class StackingClassifier (from scratch)\n",
        "class StackingClassifier:\n",
        "    def __init__(self, base_models, meta_model, n_folds=5):\n",
        "        \"\"\"\n",
        "        base_models : list\n",
        "            Daftar model dasar (misal: [DecisionTreeClassifier(), KNeighborsClassifier()])\n",
        "        meta_model : object\n",
        "            Model meta yang akan dilatih pada prediksi dari base models\n",
        "        n_folds : int\n",
        "            Jumlah fold untuk cross-validation (default = 5)\n",
        "        \"\"\"\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.n_folds = n_folds\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Melatih base models dan meta model menggunakan skema out-of-fold.\"\"\"\n",
        "        from sklearn.model_selection import KFold\n",
        "        self.base_models_ = [list() for _ in self.base_models]\n",
        "        self.meta_model_ = clone(self.meta_model)\n",
        "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
        "\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            for train_idx, holdout_idx in kfold.split(X, y):\n",
        "                instance = clone(model)\n",
        "                instance.fit(X[train_idx], y[train_idx])\n",
        "                y_pred = instance.predict(X[holdout_idx])\n",
        "                out_of_fold_predictions[holdout_idx, i] = y_pred\n",
        "                self.base_models_[i].append(instance)\n",
        "\n",
        "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Melakukan prediksi dengan menggabungkan hasil prediksi base models menggunakan meta model.\"\"\"\n",
        "        meta_features = np.column_stack([\n",
        "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
        "            for base_models in self.base_models_\n",
        "        ])\n",
        "        return self.meta_model_.predict(meta_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1cf6ff9c",
      "metadata": {
        "id": "1cf6ff9c",
        "papermill": {
          "duration": 0.014463,
          "end_time": "2024-06-29T05:07:00.969581",
          "exception": false,
          "start_time": "2024-06-29T05:07:00.955118",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### **Upload datasets**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset iris dari sklearn\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris(as_frame=True)\n",
        "glass_df = iris.frame\n",
        "\n",
        "# Pisahkan fitur dan target\n",
        "X1 = glass_df.drop(columns=[\"target\"])\n",
        "y1 = glass_df[\"target\"]\n",
        "\n",
        "# Split data menjadi train dan test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
        "\n",
        "print(\"Data train:\", X1_train.shape)\n",
        "print(\"Data test :\", X1_test.shape)"
      ],
      "metadata": {
        "id": "n5A865GHEqpX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1a4ce67-748e-4e75-a0eb-c368ac99b619"
      },
      "id": "n5A865GHEqpX",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train: (120, 4)\n",
            "Data test : (30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f91c4f4f",
      "metadata": {
        "id": "f91c4f4f",
        "papermill": {
          "duration": 0.014633,
          "end_time": "2024-06-29T05:07:01.153943",
          "exception": false,
          "start_time": "2024-06-29T05:07:01.139310",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# **Model training and evaluation of the obtained results**\n",
        "Both in the case of classification and regression, stacking and blending showed the same and not the best results. As a rule, this situation occurs for two reasons: given that metadata is based on predictions of basic models, the presence of weak basic models can reduce the accuracy of stronger ones which will reduce the final prediction as a whole. Also a small amount of training data often leads to overfitting which in turn reduces the accuracy of predictions.\n",
        "\n",
        "In this case the problem can be partially solved by setting stack_method='predict_proba' when each basic classifier outputs class membership probabilities instead of the classes themselves which can help increase accuracy in the case of non-mutually exclusive classes. Also this method works better with noise in the data. As you can see this method has significantly increased the accuracy of the model. With the right selection of models and hyperparameters the accuracy will be even higher.\n",
        "\n",
        "Most often stacking shows slightly better results than blending due to the use of k-fold cross-validation but usually the difference is noticeable only on a large amount of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf39fc7e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-29T05:07:01.215267Z",
          "iopub.status.busy": "2024-06-29T05:07:01.214854Z",
          "iopub.status.idle": "2024-06-29T05:07:10.093042Z",
          "shell.execute_reply": "2024-06-29T05:07:10.091587Z"
        },
        "id": "bf39fc7e",
        "papermill": {
          "duration": 8.8971,
          "end_time": "2024-06-29T05:07:10.095743",
          "exception": false,
          "start_time": "2024-06-29T05:07:01.198643",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# StackingClassifier dan Blending Classifier\n",
        "\n",
        "# STACKING CLASSIFIER (from scratch)\n",
        "from sklearn.base import clone\n",
        "\n",
        "class StackingClassifier:\n",
        "    def __init__(self, base_models, meta_model, n_folds=5):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.n_folds = n_folds\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        from sklearn.model_selection import KFold\n",
        "        self.base_models_ = [list() for _ in self.base_models]\n",
        "        self.meta_model_ = clone(self.meta_model)\n",
        "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
        "\n",
        "        for i, model in enumerate(self.base_models):\n",
        "            for train_idx, holdout_idx in kfold.split(X, y):\n",
        "                instance = clone(model)\n",
        "                instance.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
        "                y_pred = instance.predict(X.iloc[holdout_idx])\n",
        "                out_of_fold_predictions[holdout_idx, i] = y_pred\n",
        "                self.base_models_[i].append(instance)\n",
        "\n",
        "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
        "            for base_models in self.base_models_\n",
        "        ])\n",
        "        return self.meta_model_.predict(meta_features)\n",
        "\n",
        "# BLENDING CLASSIFIER (versi sederhana)\n",
        "class BlendingClassifier:\n",
        "    def __init__(self, base_models, meta_model, holdout_size=0.2):\n",
        "        self.base_models = base_models\n",
        "        self.meta_model = meta_model\n",
        "        self.holdout_size = holdout_size\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X_train, X_holdout, y_train, y_holdout = train_test_split(\n",
        "            X, y, test_size=self.holdout_size, random_state=42\n",
        "        )\n",
        "\n",
        "        self.base_models_ = [clone(model).fit(X_train, y_train) for model in self.base_models]\n",
        "\n",
        "        holdout_predictions = np.column_stack([\n",
        "            model.predict(X_holdout) for model in self.base_models_\n",
        "        ])\n",
        "\n",
        "        self.meta_model_ = clone(self.meta_model).fit(holdout_predictions, y_holdout)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        meta_features = np.column_stack([\n",
        "            model.predict(X) for model in self.base_models_\n",
        "        ])\n",
        "        return self.meta_model_.predict(meta_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f044880e",
      "metadata": {
        "id": "f044880e",
        "papermill": {
          "duration": 0.014779,
          "end_time": "2024-06-29T05:07:10.125840",
          "exception": false,
          "start_time": "2024-06-29T05:07:10.111061",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "**StackingClassifier (scikit-learn)**\n",
        "\n",
        "\n",
        "* Merupakan implementasi resmi stacking untuk klasifikasi dalam scikit-learn.\n",
        "\n",
        "* Mempermudah proses ensemble dengan base learners dan final estimator (meta learner) dalam satu objek.\n",
        "\n",
        "* Sudah menangani cross-validation secara internal sehingga mengurangi risiko data leakage.\n",
        "\n",
        "* Mendukung parameter passthrough=True jika ingin menggabungkan fitur asli dengan meta-features.\n",
        "\n",
        "* Cocok untuk digunakan dalam pipeline dan produksi karena stabil dan teruji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "11437b8a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-29T05:07:10.158872Z",
          "iopub.status.busy": "2024-06-29T05:07:10.157857Z",
          "iopub.status.idle": "2024-06-29T05:07:58.751416Z",
          "shell.execute_reply": "2024-06-29T05:07:58.749955Z"
        },
        "id": "11437b8a",
        "papermill": {
          "duration": 48.613356,
          "end_time": "2024-06-29T05:07:58.754310",
          "exception": false,
          "start_time": "2024-06-29T05:07:10.140954",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69040094-39a8-4a3a-963e-1438705c48f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== STACKING METHOD 1: 'predict' ===\n",
            "Akurasi : 1.0\n",
            "\n",
            "=== STACKING METHOD 2: 'predict_proba' ===\n",
            "Akurasi : 1.0\n"
          ]
        }
      ],
      "source": [
        "# StackingClassifier (scikit-learn)\n",
        "\n",
        "# STACKING CLASSIFIER (Menggunakan Scikit-Learn)\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "sk_estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=0)),\n",
        "    ('knn', KNeighborsClassifier(n_neighbors=5))\n",
        "]\n",
        "\n",
        "meta_model = LogisticRegression()\n",
        "\n",
        "stack_methods = ['predict', 'predict_proba']\n",
        "\n",
        "for i, method in enumerate(stack_methods):\n",
        "    print(f\"\\n=== STACKING METHOD {i+1}: '{method}' ===\")\n",
        "\n",
        "    sk_stack = StackingClassifier(\n",
        "        estimators=sk_estimators,\n",
        "        final_estimator=meta_model,\n",
        "        stack_method=method,\n",
        "        passthrough=False,\n",
        "        cv=5,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    sk_stack.fit(X1_train, y1_train)\n",
        "\n",
        "    y_pred = sk_stack.predict(X1_test)\n",
        "    acc = accuracy_score(y1_test, y_pred)\n",
        "    print(\"Akurasi :\", round(acc, 4))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 738,
          "sourceId": 1370,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 71.638912,
      "end_time": "2024-06-29T05:08:06.086780",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-06-29T05:06:54.447868",
      "version": "2.5.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}